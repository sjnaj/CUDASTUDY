[I] RUNNING | Command: /home/fengsc/anaconda3/envs/py37/bin/polygraphy run modelA.onnx --trt --save-engine model-02.plan --trt-min-shapes tensorX:[1,1,28,28] --trt-opt-shapes tensorX:[4,1,28,28] --trt-max-shapes tensorX:[16,1,28,28] --fp16 --pool-limit workspace:1G --input-shapes tensorX:[4,1,28,28] --verbose
[V] Loaded Module: polygraphy | Version: 0.49.0 | Path: ['/home/fengsc/anaconda3/envs/py37/lib/python3.7/site-packages/polygraphy']
[V] Loaded extension modules: []
[I] Will generate inference input data according to provided TensorMetadata: {tensorX [shape=(4, 1, 28, 28)]}
[V] Loaded Module: tensorrt | Version: 8.5.1.7 | Path: ['/home/fengsc/anaconda3/envs/py37/lib/python3.7/site-packages/tensorrt']
[I] trt-runner-N0-01/03/24-11:24:59     | Activating and starting inference
[V] [MemUsageChange] Init CUDA: CPU +204, GPU +0, now: CPU 220, GPU 481 (MiB)
[V] [MemUsageChange] Init builder kernel library: CPU +121, GPU +22, now: CPU 396, GPU 503 (MiB)
[W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage. See `CUDA_MODULE_LOADING` in https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars
[V] ----------------------------------------------------------------
[V] Input filename:   /home/fengsc/CUDASTUDY/trt-samples-for-hackathon-cn/cookbook/07-Tool/Polygraphy-CLI/RunExample/modelA.onnx
[V] ONNX IR version:  0.0.8
[V] Opset version:    11
[V] Producer name:    
[V] Producer version: 
[V] Domain:           
[V] Model version:    0
[V] Doc string:       
[V] ----------------------------------------------------------------
[W] onnx2trt_utils.cpp:377: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.
[W] Tensor DataType is determined at build time for tensors not marked as input or output.
[V] Setting TensorRT Optimization Profiles
[V] Input tensor: tensorX (dtype=DataType.FLOAT, shape=(-1, 1, 28, 28)) | Setting input tensor shapes to: (min=[1, 1, 28, 28], opt=[4, 1, 28, 28], max=[16, 1, 28, 28])
[I] Configuring with profiles:[
        Profile 0:
            {tensorX [min=[1, 1, 28, 28], opt=[4, 1, 28, 28], max=[16, 1, 28, 28]]}
    ]
[I] Building engine with configuration:
    Flags                  | [FP16]
    Engine Capability      | EngineCapability.DEFAULT
    Memory Pools           | [WORKSPACE: 1024.00 MiB]
    Tactic Sources         | [CUBLAS, CUBLAS_LT, CUDNN, EDGE_MASK_CONVOLUTIONS, JIT_CONVOLUTIONS]
    Profiling Verbosity    | ProfilingVerbosity.DETAILED
[V] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +255, GPU +106, now: CPU 676, GPU 609 (MiB)
[V] [MemUsageChange] Init cuDNN: CPU +111, GPU +44, now: CPU 787, GPU 653 (MiB)
[V] Global timing cache in use. Profiling results in this builder pass will be stored.
[V] Total Activation Memory: 1077423104
[V] Detected 1 inputs and 2 output network tensors.
[V] Total Host Persistent Memory: 9664
[V] Total Device Persistent Memory: 10752
[V] Total Scratch Memory: 512
[V] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 36 MiB, GPU 438 MiB
[V] [BlockAssignment] Started assigning block shifts. This will take 14 steps to complete.
[V] [BlockAssignment] Algorithm ShiftNTopDown took 0.1282ms to assign 4 blocks to 14 nodes requiring 2408960 bytes.
[V] Total Activation Memory: 2408960
[V] [MemUsageChange] Init cuDNN: CPU +1, GPU +10, now: CPU 1150, GPU 823 (MiB)
[W] TensorRT encountered issues when converting weights between types and that could affect accuracy.
[W] If this is not the desired behavior, please modify the weights or retrain with regularization to adjust the magnitude of the weights.
[W] Check verbose logs for the list of affected weights.
[W] - 3 weights are affected by this issue: Detected subnormal FP16 values.
[V] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +12, GPU +13, now: CPU 12, GPU 13 (MiB)
[I] Finished engine building in 11.978 seconds
[V] Loaded engine size: 12 MiB
[V] [MemUsageChange] Init cuDNN: CPU +1, GPU +10, now: CPU 1150, GPU 807 (MiB)
[V] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +12, now: CPU 0, GPU 12 (MiB)
[V] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 1137, GPU 807 (MiB)
[V] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +2, now: CPU 0, GPU 14 (MiB)
[V] Found candidate CUDA libraries: ['/usr/local/cuda/lib64/libcudart.so.11.7.60', '/usr/local/cuda/lib64/libcudart.so.11.0', '/usr/local/cuda/lib64/libcudart.so']
[V] Loading inputs from data loader
[V] Generating data using numpy seed: 1
[V] Loaded Module: numpy | Version: 1.21.6 | Path: ['/home/fengsc/anaconda3/envs/py37/lib/python3.7/site-packages/numpy']
[V] Input tensor: tensorX | Generating input data in range: [0.0, 1.0]
[V] Loaded Module: torch | Version: 1.13.0 | Path: ['/home/fengsc/anaconda3/envs/py37/lib/python3.7/site-packages/torch']
[I] trt-runner-N0-01/03/24-11:24:59    
    ---- Inference Input(s) ----
    {tensorX [dtype=float32, shape=(4, 1, 28, 28)]}
[V] trt-runner-N0-01/03/24-11:24:59     | Input metadata is: {tensorX [dtype=float32, shape=(-1, 1, 28, 28)]}
[I] trt-runner-N0-01/03/24-11:24:59    
    ---- Inference Output(s) ----
    {A-V-12-Add [dtype=float32, shape=(4, 10)],
     A-V-14-ArgMax [dtype=int32, shape=(4,)]}
[I] trt-runner-N0-01/03/24-11:24:59     | Completed 1 iteration(s) in 2478 ms | Average inference time: 2478 ms.
[V] Successfully ran: ['trt-runner-N0-01/03/24-11:24:59']
[I] PASSED | Runtime: 18.820s | Command: /home/fengsc/anaconda3/envs/py37/bin/polygraphy run modelA.onnx --trt --save-engine model-02.plan --trt-min-shapes tensorX:[1,1,28,28] --trt-opt-shapes tensorX:[4,1,28,28] --trt-max-shapes tensorX:[16,1,28,28] --fp16 --pool-limit workspace:1G --input-shapes tensorX:[4,1,28,28] --verbose
