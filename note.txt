conda clean -p
conda clean -t
pip cache purge
sudo du -h xx | sort -h

np.ascontiguousarray 函数将一个内存不连续存储的数组转换为内存连续存储的数组
ONNX：open neural network exchange

不支持9，改为8
/home/fengsc/anaconda3/envs/py37/lib/python3.7/site-packages/onnx_graphsurgeon/exporters/onnx_exporter.py:181:    model.ir_version=8

浮点模型 : 模型的权重和激活均为浮点类型

量化模型 : 均为量化类型

训练后量化 : 简称 PTQ（Post Training Quantization）
/home/fengsc/CUDASTUDY/trt-samples-for-hackathon-cn/cookbook/04-BuildEngineByONNXParser/pyTorch-ONNX-TensorRT/main.py


量化校准（标定）
calibration：https://zhuanlan.zhihu.com/p/516116539
Nvidia calibration:
In post-training quantization, TensorRT computes a scale value for each tensor in the network. 
This process, called calibration, requires you to supply representative input data on which TensorRT runs the network to collect statistics for each activation tensor.

IInt8MinMaxCalibrator 和 IInt8EntropyCalibrator2，前者适用于 NLP 任务，后者适用于 CNN 任务

先在一个校准数据集上跑一遍原FP32的模型；
然后，对每一层都收集激活值的直方图，并生成在不同阈值下的饱和量化分布；
最后，找出使得KL散度最小的那个阈值T，即为所求。


静态量化感知训练 : 简称 QAT（static quantization aware training）
利用pytorch_quantization.nn搭建模型训练
/home/fengsc/CUDASTUDY/trt-samples-for-hackathon-cn/cookbook/04-BuildEngineByONNXParser/pyTorch-ONNX-TensorRT-QAT/main.py

.pt->onnx->Parser(Builder/trtexec)->engine(serialize)->engine(deserialize)->context

/home/fengsc/CUDASTUDY/trt-samples-for-hackathon-cn/cookbook/05-Plugin/UseONNXParserAndPlugin-pyTorch

batchedNMSPlugin 

Timing Cache:为了减少构建器时间，TensorRT 创建了一个层时序缓存，以在构建器阶段保存层分析信息。

优化单次引擎构建时间（模型内多个同参数的算子）
➢ 优化多次引擎构建时间（debug、参数更新后重新构建）
➢ 优化同环境下多个引擎构建时间（跨 builder 可用）
➢ 用于反复生成一模一样的引擎
➢ 要点
➢ 类似引擎序列化反序列化，将 Timing Cache 保存出来下次用
➢ 类似 .engine，不可跨平台和开发环境使用


添加plugin两种方式，trt或者onnx_graphsurgeon

 registry = trt.get_plugin_registry()
            assert(registry)
            creator = registry.get_plugin_creator("EfficientNMS_TRT", "1")
            assert(creator)
            fc = []
            fc.append(trt.PluginField("background_class", np.array([-1], dtype=np.int32), trt.PluginFieldType.INT32))
            fc.append(trt.PluginField("max_output_boxes", np.array([max_det], dtype=np.int32), trt.PluginFieldType.INT32))
            fc.append(trt.PluginField("score_threshold", np.array([conf_thres], dtype=np.float32), trt.PluginFieldType.FLOAT32))
            fc.append(trt.PluginField("iou_threshold", np.array([iou_thres], dtype=np.float32), trt.PluginFieldType.FLOAT32))
            fc.append(trt.PluginField("box_coding", np.array([1], dtype=np.int32), trt.PluginFieldType.INT32))
            fc.append(trt.PluginField("score_activation", np.array([0], dtype=np.int32), trt.PluginFieldType.INT32))
            
            fc = trt.PluginFieldCollection(fc) 
            nms_layer = creator.create_plugin("nms_layer", fc)

            layer = self.network.add_plugin_v2([boxes.get_output(0), scores.get_output(0)], nms_layer)
            layer.get_output(0).name = "num"
            layer.get_output(1).name = "boxes"
            layer.get_output(2).name = "scores"
            layer.get_output(3).name = "classes"


    for node in graph.nodes:
    if node.op == "Add":
        scalar = float(node.i(1).attrs["value"].values)
        pluginV = gs.Variable("MyAddPluginVariable-%d" % nPlugin, np.dtype(np.float32), None)
        pluginN = gs.Node("AddScalar", "MyAddPluginNode-%d" % nPlugin, inputs=[node.inputs[0]], outputs=[pluginV], attrs={"scalar": float(scalar)})
        graph.nodes.append(pluginN)
        node.o().inputs[0] = pluginV
        node.outputs.clear()
        nPlugin += 1

graph.cleanup()


onnx模型建立  torch接口，onnx_graphsurgeon搭建

trt模型建立  手动建立，onnx_parse,torch接口（troch.jit.trace）

添加插件  ：trt模型上添加，onnx模型上添加：05-Plugin/UseONNXParserAndPlugin-pyTorch/main.py

插件框架  ：

trt模型保存（build_serialized_network）

trt模型加载（deserialize_cuda_engine），torch接口（torch_tensorrt.compile）

trt模型执行：  配置输入输出缓存（alloc，cpy）->createExecutionContext()->enqueueV3（c++） ，execute_async_v3（python）->收集结果（cpy，free）

V2: replacement of enqueue, support explict batch. is deprecated now.
V3: latest api, support data dependent shape, recommend to use now.

NMS利用GPU优化：1，将模型输出传入gpu进行后处理  2，在模型输出上插入插件，实现端到端。

fp16，int8，
1, 3, 640, 640
python export.py -o /home/fengsc/CUDASTUDY/Yolo_TensorRt/yolov8n.onnx -p int8 -e yolov8n_int8.engine --end2end --v8 --calib_input ./src/

查看信息
trtexec --verbose --profilingVerbosity=detailed --noDataTransfers --useCudaGraph --separateProfileRun --useSpinWait --loadEngine=./model/model.plan --exportProfile=./model/profile.json --exportTimes=./model/profile.timing.json --exportLayerInfo=./model/graph.json --plugins=/home/fengsc/CUDASTUDY/Yolo_TensorRt/AddScalar/AddScalarPlugin.so
python trt.py -e /home/fengsc/CUDASTUDY/Yolo_TensorRt/TensorRT-For-YOLO-Series/yolov8n_int8.engine -i /home/fengsc/CUDASTUDY/Yolo_TensorRt/TensorRT-For-YOLO-Series/src/group.jpg -o /home/fengsc/CUDASTUDY/Yolo_TensorRt/TensorRT-For-YOLO-Series/src/res.jpg --end2end 

自定义插件，生产者消费者

onnx优化

 polygraphy surgeon sanitize --fold-constant yolov8n.onnx -o yolov8n_sanitized.onnx >result-01.log
 yolo导出的模型优化足够好，上述命令不能继续优化

 onnxsim yolov8n.onnx yolov8n_sim.onnx，与上面命令作用类似，但也没有实际优化

 onnx-graphsungeon（自由度最高）
Function:
  + Modify metadata/node / tensor / weight data of compute graph.
  + Modify subgraph: Add / Delete / Replace / Isolate
  + Optimize: constant folding / topological sorting / removing useless layers.

graph.fold_constants()
graph.fold_constants().cleanup()#清除被优化掉的孤立node

一个SM上执行一个或多个线程块
一个warp在SM上以SIMD方式锁步执行
对于小于等于32个线程，同步是多余的
extern，shared：块共享，动态分配和静态分配
shlf_down_sync 执行tree-reduction，warp内跨线程访问，mask：32位掩码，结果在0号lane上
__shfl_xor_sync:当前线程的lane_id值与offset做xor，然后把结果处的val变量值取来。
执行butterfly reduction（蝶形规约），求和或求最值，结果在所有lane上，适合需要广播的情形。

warp_reduce,block_reduce(warp->shared->warp)
warp level Primitives:https://zhuanlan.zhihu.com/p/572820783

reduce：__shfl_down_sync规约（操作寄存器，无视bank冲突），每个线程首先存储多个位置的和，增加固定任务，来实现线程之间的负载均衡
  int num_blocks = std::max<int>(1, std::min<int>((n + BLOCK_SIZE - 1) / BLOCK_SIZE,
                                                                sm_count * tpm / BLOCK_SIZE));
PyTorch Block Reduce：

shared_mem在内存中以32*4B的宽度二维存放，每一个4B宽带的列代表一个bank

所有SM共享L2 Cache，拥有私有的L1 Cache，私有的Shared Memory和私有的寄存器堆。

一个Block能且只能在一个SM中运行，一个SM可以同时运行多个Block；在SM中，一个Block的线程按照32的粒度分组，每32个线程称为一个Warp，
Warp是SM调度运行的最小单位（(新架构可以并行4个warp)，每个时钟周期，SM Block都会尝试选择一个可以调度的Warp发射执行

Grid在全局内存Global Memory中共享数据，Block在共享内存Shared Memory中共享数据；SM中的寄存器是线程私有

矩阵分块（带），float4，LDG.128和STG.128
bank冲突：shared_mem。读取矩阵A时在shared_mem装置（因为一次读一个长为k（窄带宽度）的列向量）
双缓冲预取。本次运算和下次传输并行先load到本地寄存器，计算完后从寄存器写回shared_mem，load和计算不存在数据依赖，可以并行）

置信度排序，iou去重。
