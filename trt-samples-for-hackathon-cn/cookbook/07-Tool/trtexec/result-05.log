&&&& RUNNING TensorRT.trtexec [TensorRT v8501] # trtexec --loadEngine=./model-02.plan --dumpProfile --exportTimes=./model-02-exportTimes.json --exportProfile=./model-02-exportProfile.json
[01/02/2024-22:53:36] [I] === Model Options ===
[01/02/2024-22:53:36] [I] Format: *
[01/02/2024-22:53:36] [I] Model: 
[01/02/2024-22:53:36] [I] Output:
[01/02/2024-22:53:36] [I] === Build Options ===
[01/02/2024-22:53:36] [I] Max batch: 1
[01/02/2024-22:53:36] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default
[01/02/2024-22:53:36] [I] minTiming: 1
[01/02/2024-22:53:36] [I] avgTiming: 8
[01/02/2024-22:53:36] [I] Precision: FP32
[01/02/2024-22:53:36] [I] LayerPrecisions: 
[01/02/2024-22:53:36] [I] Calibration: 
[01/02/2024-22:53:36] [I] Refit: Disabled
[01/02/2024-22:53:36] [I] Sparsity: Disabled
[01/02/2024-22:53:36] [I] Safe mode: Disabled
[01/02/2024-22:53:36] [I] DirectIO mode: Disabled
[01/02/2024-22:53:36] [I] Restricted mode: Disabled
[01/02/2024-22:53:36] [I] Build only: Disabled
[01/02/2024-22:53:36] [I] Save engine: 
[01/02/2024-22:53:36] [I] Load engine: ./model-02.plan
[01/02/2024-22:53:36] [I] Profiling verbosity: 0
[01/02/2024-22:53:36] [I] Tactic sources: Using default tactic sources
[01/02/2024-22:53:36] [I] timingCacheMode: local
[01/02/2024-22:53:36] [I] timingCacheFile: 
[01/02/2024-22:53:36] [I] Heuristic: Disabled
[01/02/2024-22:53:36] [I] Preview Features: Use default preview flags.
[01/02/2024-22:53:36] [I] Input(s)s format: fp32:CHW
[01/02/2024-22:53:36] [I] Output(s)s format: fp32:CHW
[01/02/2024-22:53:36] [I] Input build shapes: model
[01/02/2024-22:53:36] [I] Input calibration shapes: model
[01/02/2024-22:53:36] [I] === System Options ===
[01/02/2024-22:53:36] [I] Device: 0
[01/02/2024-22:53:36] [I] DLACore: 
[01/02/2024-22:53:36] [I] Plugins:
[01/02/2024-22:53:36] [I] === Inference Options ===
[01/02/2024-22:53:36] [I] Batch: 1
[01/02/2024-22:53:36] [I] Input inference shapes: model
[01/02/2024-22:53:36] [I] Iterations: 10
[01/02/2024-22:53:36] [I] Duration: 3s (+ 200ms warm up)
[01/02/2024-22:53:36] [I] Sleep time: 0ms
[01/02/2024-22:53:36] [I] Idle time: 0ms
[01/02/2024-22:53:36] [I] Streams: 1
[01/02/2024-22:53:36] [I] ExposeDMA: Disabled
[01/02/2024-22:53:36] [I] Data transfers: Enabled
[01/02/2024-22:53:36] [I] Spin-wait: Disabled
[01/02/2024-22:53:36] [I] Multithreading: Disabled
[01/02/2024-22:53:36] [I] CUDA Graph: Disabled
[01/02/2024-22:53:36] [I] Separate profiling: Disabled
[01/02/2024-22:53:36] [I] Time Deserialize: Disabled
[01/02/2024-22:53:36] [I] Time Refit: Disabled
[01/02/2024-22:53:36] [I] NVTX verbosity: 0
[01/02/2024-22:53:36] [I] Persistent Cache Ratio: 0
[01/02/2024-22:53:36] [I] Inputs:
[01/02/2024-22:53:36] [I] === Reporting Options ===
[01/02/2024-22:53:36] [I] Verbose: Disabled
[01/02/2024-22:53:36] [I] Averages: 10 inferences
[01/02/2024-22:53:36] [I] Percentiles: 90,95,99
[01/02/2024-22:53:36] [I] Dump refittable layers:Disabled
[01/02/2024-22:53:36] [I] Dump output: Disabled
[01/02/2024-22:53:36] [I] Profile: Enabled
[01/02/2024-22:53:36] [I] Export timing to JSON file: ./model-02-exportTimes.json
[01/02/2024-22:53:36] [I] Export output to JSON file: 
[01/02/2024-22:53:36] [I] Export profile to JSON file: ./model-02-exportProfile.json
[01/02/2024-22:53:36] [I] 
[01/02/2024-22:53:37] [I] === Device Information ===
[01/02/2024-22:53:37] [I] Selected Device: NVIDIA GeForce MX350
[01/02/2024-22:53:37] [I] Compute Capability: 6.1
[01/02/2024-22:53:37] [I] SMs: 5
[01/02/2024-22:53:37] [I] Compute Clock Rate: 1.468 GHz
[01/02/2024-22:53:37] [I] Device Global Memory: 2047 MiB
[01/02/2024-22:53:37] [I] Shared Memory per SM: 96 KiB
[01/02/2024-22:53:37] [I] Memory Bus Width: 64 bits (ECC disabled)
[01/02/2024-22:53:37] [I] Memory Clock Rate: 3.504 GHz
[01/02/2024-22:53:37] [I] 
[01/02/2024-22:53:37] [I] TensorRT version: 8.5.1
[01/02/2024-22:53:37] [I] Engine loaded in 0.0216516 sec.
[01/02/2024-22:53:38] [I] [TRT] Loaded engine size: 12 MiB
[01/02/2024-22:53:38] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +272, GPU +112, now: CPU 360, GPU 531 (MiB)
[01/02/2024-22:53:38] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +12, now: CPU 0, GPU 12 (MiB)
[01/02/2024-22:53:38] [I] Engine deserialized in 1.27191 sec.
[01/02/2024-22:53:38] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 360, GPU 531 (MiB)
[01/02/2024-22:53:38] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +2, now: CPU 0, GPU 14 (MiB)
[01/02/2024-22:53:38] [I] Setting persistentCacheLimit to 0 bytes.
[01/02/2024-22:53:38] [W] Shape missing for input with dynamic shape: tensorXAutomatically setting shape to: 1x1x28x28
[01/02/2024-22:53:38] [I] Using random values for input tensorX
[01/02/2024-22:53:38] [I] Created input binding for tensorX with dimensions 1x1x28x28
[01/02/2024-22:53:38] [I] Using random values for output A-V-12-Add
[01/02/2024-22:53:38] [I] Created output binding for A-V-12-Add with dimensions 1x10
[01/02/2024-22:53:38] [I] Using random values for output A-V-14-ArgMax
[01/02/2024-22:53:38] [I] Created output binding for A-V-14-ArgMax with dimensions 1
[01/02/2024-22:53:38] [I] Starting inference
[01/02/2024-22:53:42] [I] The e2e network timing is not reported since it is inaccurate due to the extra synchronizations when the profiler is enabled.
[01/02/2024-22:53:42] [I] To show e2e network timing report, add --separateProfileRun to profile layer timing in a separate run or remove --dumpProfile to disable the profiler.
[01/02/2024-22:53:42] [I] 
[01/02/2024-22:53:42] [I] === Profile (4126 iterations ) ===
[01/02/2024-22:53:42] [I]                                                                                                      Layer   Time (ms)   Avg. Time (ms)   Median Time (ms)   Time %
[01/02/2024-22:53:42] [I]                                                                                    A-N-0-Conv + A-N-1-Relu       75.88           0.0184             0.0184      3.7
[01/02/2024-22:53:42] [I]                                                                                              A-N-2-MaxPool       26.27           0.0064             0.0061      1.3
[01/02/2024-22:53:42] [I]                                        Reformatting CopyNode for Input Tensor 0 to A-N-3-Conv + A-N-4-Relu       28.01           0.0068             0.0071      1.4
[01/02/2024-22:53:42] [I]                                                                                    A-N-3-Conv + A-N-4-Relu      166.23           0.0403             0.0410      8.0
[01/02/2024-22:53:42] [I]                                                                                              A-N-5-MaxPool       24.18           0.0059             0.0061      1.2
[01/02/2024-22:53:42] [I]                                              A-N-6-Transpose + A-N-7-Reshape + reshape_before_A-N-8-MatMul       17.96           0.0044             0.0041      0.9
[01/02/2024-22:53:42] [I]                                                                                 A-N-8-MatMul + A-N-10-Relu     1648.65           0.3996             0.3799     79.5
[01/02/2024-22:53:42] [I]                                                                                              A-N-11-MatMul       60.13           0.0146             0.0143      2.9
[01/02/2024-22:53:42] [I]                                                                             A-N-13-Softmax + A-N-14-ArgMax       26.55           0.0064             0.0061      1.3
[01/02/2024-22:53:42] [I]                                                                                                      Total     2073.86           0.5026             0.4823    100.0
[01/02/2024-22:53:42] [I] 
&&&& PASSED TensorRT.trtexec [TensorRT v8501] # trtexec --loadEngine=./model-02.plan --dumpProfile --exportTimes=./model-02-exportTimes.json --exportProfile=./model-02-exportProfile.json
