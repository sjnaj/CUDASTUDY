#!/usr/bin/env python3
# Template auto-generated by polygraphy [v0.49.0] on 01/03/24 at 11:26:00
# Generation Command: /home/fengsc/anaconda3/envs/py37/bin/polygraphy run modelA.onnx --trt --save-engine model-02.plan --trt-min-shapes tensorX:[1,1,28,28] --trt-opt-shapes tensorX:[4,1,28,28] --trt-max-shapes tensorX:[16,1,28,28] --fp16 --pool-limit workspace:1G --input-shapes tensorX:[4,1,28,28] --silent --gen-script=./polygraphyRun.py
# This script runs /home/fengsc/CUDASTUDY/trt-samples-for-hackathon-cn/cookbook/07-Tool/Polygraphy-CLI/RunExample/modelA.onnx using TensorRT.

from polygraphy.logger import G_LOGGER
G_LOGGER.module_severity = G_LOGGER.CRITICAL

from polygraphy import mod
from polygraphy.backend.common import SaveBytes
from polygraphy.backend.trt import CreateConfig as CreateTrtConfig, EngineBytesFromNetwork, EngineFromBytes, NetworkFromOnnxPath, Profile, TrtRunner
from polygraphy.common import TensorMetadata
from polygraphy.comparator import Comparator, DataLoader
from polygraphy.exception import PolygraphyException
trt = mod.lazy_import('tensorrt')

# Data Loader
data_loader = DataLoader(input_metadata=TensorMetadata().add('tensorX', None, [4, 1, 28, 28]))

# Loaders
parse_network_from_onnx = NetworkFromOnnxPath('/home/fengsc/CUDASTUDY/trt-samples-for-hackathon-cn/cookbook/07-Tool/Polygraphy-CLI/RunExample/modelA.onnx')
profiles = [
    Profile().add('tensorX', min=[1, 1, 28, 28], opt=[4, 1, 28, 28], max=[16, 1, 28, 28])
]
create_trt_config = CreateTrtConfig(fp16=True, profiles=profiles, memory_pool_limits={trt.MemoryPoolType.WORKSPACE: 1073741824})
build_engine = EngineBytesFromNetwork(parse_network_from_onnx, config=create_trt_config)
save_engine_bytes = SaveBytes(build_engine, path='model-02.plan')
deserialize_engine = EngineFromBytes(save_engine_bytes)

# Runners
runners = [
    TrtRunner(deserialize_engine),
]

# Runner Execution
results = Comparator.run(runners, data_loader=data_loader)

success = True

# Report Results
if not success:
    raise PolygraphyException('FAILED')
